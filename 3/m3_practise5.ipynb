{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4580bc-40bc-4356-94e5-ff5328e56f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b84ee082-2772-4e99-b310-318813a3ed50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dex/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_boston()\n",
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "59a25fd9-d55c-4899-839a-5e1b240d95b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86ee7a3f-5f74-4c31-98ba-01e1d1ae24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg_linear(X, y):\n",
    "    theta = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.transpose(), X)), X.transpose()), y) #np.linalg.inv = ^(-1)\n",
    "    \n",
    "    ###\n",
    "    z = X\n",
    "    mat=np.matmul(z.transpose(),z); # product of z and z transpose\n",
    "    matinv=np.linalg.inv(mat) #inverse of above product\n",
    "    val=np.matmul(matinv,z.transpose()) # Product of inverse and z transpose\n",
    "    theta=np.matmul(val,y) # Value of theta by multiplying value calculated above to y\n",
    "    ###\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "56c29f26-94e2-4f97-ab97-1353d9d9118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовить данные\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])#добавляем столбец 1-ц в X. Нужно, чтобы сэмулировать b (y=kx+b)\n",
    "#np.ones(X.shape[0]) - строим столбец из единиц\n",
    "#[:, np.newaxis] - приводим его к двухмерной матрице / делаем из него столбец\n",
    "#np.hstack - добавляем как еще один столбец к X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e1491387-e33f-4158-8eff-95349b149d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислить параметр theta\n",
    "theta = linreg_linear(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9612ff9d-d5cf-49f6-ba99-c1c6373c3ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape #размер вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a6d7d7d4-f09e-48f0-ba0e-e3046a9e691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания для тренировочной выборки\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "82fcab22-07b5-4d75-ae02-7ad8963cd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ae73b0c6-5f1f-4dbe-a7fc-a5d7741a83ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "096465a4-cb72-41a1-aab9-7efd7f82cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, вычислить theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = linreg_linear(X_train, y_train)\n",
    "y_pred = X_valid.dot(theta)\n",
    "y_train_pred = X_train.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "344928e2-17fb-4f5e-99ad-1d2903069c60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 29.01, RMSE = 5.39\n",
      "MSE = 20.38, RMSE = 4.51\n"
     ]
    }
   ],
   "source": [
    "print_regression_metrics(y_valid, y_pred)\n",
    "print_regression_metrics(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0608c5-e655-42c0-94a4-db9ee3eeb534",
   "metadata": {},
   "source": [
    "#### 3.5.3 Чему равно наибольшее стандартное отклонение у признаков?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d90c059c-ab8e-4cc1-8f49-b665c03b524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4ff01980-4fff-41d9-9625-1b8e8f5e970d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.    ,  88.9762, 100.    ,  27.74  ,   1.    ,   0.871 ,\n",
       "         8.78  , 100.    ,  12.1265,  24.    , 711.    ,  22.    ,\n",
       "       396.9   ,  37.97  ])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверить максимальные значения по каждому признаку в данных\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f93faf91-502b-47e9-9e10-70f0f1df741b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16951/3095098898.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mind_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "ind_max = np.argmax(X.std(axis=0)) - 1  #возвращает индекс максимального значения вдоль указанной оси\n",
    "#std(X) в случае одномерного массива возвращает стандартное отклонение элементов массива\n",
    "#std(X) в случае двумерного массива - это вектор-строка, содержащая стандартное отклонение элементов каждого столбца\n",
    "ind_max\n",
    "np.max(X[ind_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "90d136fd-7aa6-405b-8561-79399835ae51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names'][np.argmax(X.std(axis=0)) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3b805a8d-20eb-49e1-954c-d34b497732a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "168.3704950393814\n"
     ]
    }
   ],
   "source": [
    "print(data['feature_names'][np.argmax(X.std(axis=0)) + 1])\n",
    "print(np.max(X.std(axis=0)))#наибольшее стандартное отклонение у признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70983b-a55e-466a-aad3-993b85181ee5",
   "metadata": {},
   "source": [
    "#### 3.5.4 Обучите регрессию без дополнительного столбца единиц. Какой получился RMSE? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4100ce45-1b53-4ea1-9023-a030da497835",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dex/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = load_boston()\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "reg = LinearRegression()#this is must for the task 3.5.4\n",
    "reg.fit(X, y)\n",
    "y_pred = reg.predict(X)\n",
    "print_regression_metrics(y, y_pred) #4.68 is the correct answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff4f23b-e595-43b9-971c-229bf5b026f9",
   "metadata": {},
   "source": [
    "#### 3.5.5 Очистите данные от строк, где значение признака B меньше 50. Какой получился RMSE? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "05c80298-851c-418e-91fe-828cd9b8bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#переделываем датасет в датафрейм\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "18633f51-0c89-48ba-bd8b-41315e4ab226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#в датафрейме находим индексы записей, у которых в столбце B значение меньше 50\n",
    "i=df.index[df['B'] < 50].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "53df5fb6-c109-481f-9a6b-8d10506bfb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#выбираем в Х признаки, а в Y целевые переменные\n",
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d27e28fe-c5bd-41b0-9479-13ccd1493b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляем из np.array строки согласно индексам из датафрейма\n",
    "X = np.delete(X, i, axis=0)\n",
    "y = np.delete(y, i, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fea65ea8-6212-46c0-ac46-7195ae6d6087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.79, RMSE = 4.67\n"
     ]
    }
   ],
   "source": [
    "reg_355 = LinearRegression()\n",
    "reg_355.fit(X, y)\n",
    "y_pred = reg_355.predict(X)\n",
    "print_regression_metrics(y, y_pred) #4.67 in the correct answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
