{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Логистическая регрессия. Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки для логистической регрессии в случае бинарной классификации называется бинарной кросс-энтропией и записывается следующим образом:\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i))),$$\n",
    "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
    "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответствующий градиент функции ошибки равен:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация логистической регрессии будет основана на оптимизации функции ошибки градиентным спуском."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве экспериментальных данных возьмем датасет о доходах граждан в различных странах [Adult Income](https://archive.ics.uci.edu/ml/datasets/Adult) и сделаем необходимую предобработку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./3.9_adult.data',\n",
    "                    names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                           'education-num', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'capital-gain',\n",
    "                           'capital-loss', 'hours-per-week', 'native-country', 'salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание датасета\n",
    "\n",
    "# with open('./data/adult.names', 'r') as f:\n",
    "#     names = f.read()\n",
    "# print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "\n",
       "        marital-status        occupation    relationship    race    sex  \\\n",
       "0        Never-married      Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse   Exec-managerial         Husband   White   Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  salary  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Избавиться от лишних признаков\n",
    "adult.drop(['native-country'], axis=1, inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   salary  workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  ...  \\\n",
       "0       0             0                       0                     0  ...   \n",
       "1       0             0                       0                     0  ...   \n",
       "2       0             0                       0                     0  ...   \n",
       "3       0             0                       0                     0  ...   \n",
       "4       0             0                       0                     0  ...   \n",
       "\n",
       "   relationship_ Own-child  relationship_ Unmarried  relationship_ Wife  \\\n",
       "0                        0                        0                   0   \n",
       "1                        0                        0                   0   \n",
       "2                        0                        0                   0   \n",
       "3                        0                        0                   0   \n",
       "4                        0                        0                   1   \n",
       "\n",
       "   race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  race_ Black  \\\n",
       "0                         0                         0            0   \n",
       "1                         0                         0            0   \n",
       "2                         0                         0            0   \n",
       "3                         0                         0            1   \n",
       "4                         0                         0            1   \n",
       "\n",
       "   race_ Other  race_ White  sex_ Female  sex_ Male  \n",
       "0            0            1            0          1  \n",
       "1            0            1            0          1  \n",
       "2            0            1            0          1  \n",
       "3            0            0            0          1  \n",
       "4            0            0            1          0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030671</td>\n",
       "      <td>-1.063611</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>0.148453</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837109</td>\n",
       "      <td>-1.008707</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-2.222153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042642</td>\n",
       "      <td>0.245079</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.057047</td>\n",
       "      <td>0.425801</td>\n",
       "      <td>-1.197459</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775768</td>\n",
       "      <td>1.408176</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "0  0.030671 -1.063611       1.134739      0.148453      -0.21666   \n",
       "1  0.837109 -1.008707       1.134739     -0.145920      -0.21666   \n",
       "2 -0.042642  0.245079      -0.420060     -0.145920      -0.21666   \n",
       "3  1.057047  0.425801      -1.197459     -0.145920      -0.21666   \n",
       "4 -0.775768  1.408176       1.134739     -0.145920      -0.21666   \n",
       "\n",
       "   hours-per-week  salary  workclass_ ?  workclass_ Federal-gov  \\\n",
       "0       -0.035429       0             0                       0   \n",
       "1       -2.222153       0             0                       0   \n",
       "2       -0.035429       0             0                       0   \n",
       "3       -0.035429       0             0                       0   \n",
       "4       -0.035429       0             0                       0   \n",
       "\n",
       "   workclass_ Local-gov  ...  relationship_ Own-child  \\\n",
       "0                     0  ...                        0   \n",
       "1                     0  ...                        0   \n",
       "2                     0  ...                        0   \n",
       "3                     0  ...                        0   \n",
       "4                     0  ...                        0   \n",
       "\n",
       "   relationship_ Unmarried  relationship_ Wife  race_ Amer-Indian-Eskimo  \\\n",
       "0                        0                   0                         0   \n",
       "1                        0                   0                         0   \n",
       "2                        0                   0                         0   \n",
       "3                        0                   0                         0   \n",
       "4                        0                   1                         0   \n",
       "\n",
       "   race_ Asian-Pac-Islander  race_ Black  race_ Other  race_ White  \\\n",
       "0                         0            0            0            1   \n",
       "1                         0            0            0            1   \n",
       "2                         0            0            0            1   \n",
       "3                         0            1            0            0   \n",
       "4                         0            1            0            0   \n",
       "\n",
       "   sex_ Female  sex_ Male  \n",
       "0            0          1  \n",
       "1            0          1  \n",
       "2            0          1  \n",
       "3            0          1  \n",
       "4            1          0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию sigmoid\n",
    "def sigmoid(X, theta):\n",
    "    return 1. / (1. + np.exp(-X.dot(theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию, вычисляющую градиент бинарной кросс-энтропии\n",
    "def calc_binary_cross_entropy_grad(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(sigmoid(X, theta) - y)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.18220152e+00,  5.34420479e-01,  3.95775461e-01,  6.21876481e-01,\n",
       "        7.68917996e-01,  3.38583874e-01,  4.91984312e-01,  2.36520366e-01,\n",
       "        6.93612812e-03,  9.64814314e-01,  7.61509306e-01,  5.53494533e-01,\n",
       "        1.61096748e+00, -4.28230037e-01,  6.11752440e-01,  2.58558666e-01,\n",
       "        5.89057982e-01,  9.87311090e-01,  1.05574662e+00,  1.02543563e+00,\n",
       "       -3.15524980e-01,  6.18223280e-01,  9.74747564e-01, -1.59850366e-02,\n",
       "        9.09710550e-01,  9.33962074e-01,  6.08930383e-01,  9.78308166e-01,\n",
       "        9.48510850e-01, -1.39716497e+00,  7.79500017e-02,  5.20449527e-01,\n",
       "        3.24397258e-01,  1.42333149e+00, -2.97874470e-01,  1.02420428e+00,\n",
       "        8.35398252e-01,  6.90788800e-01,  8.11280626e-01,  8.58881427e-01,\n",
       "        8.98087390e-01,  2.28275110e-02,  3.30697269e-01,  2.32468515e-01,\n",
       "        1.59897859e-01,  1.08787945e+00,  3.36378365e-01,  8.85025416e-01,\n",
       "        4.35222964e-01,  5.62066615e-01, -7.81877921e-02,  2.21719660e+00,\n",
       "       -6.37888463e-01,  4.08394474e-01,  3.38009780e-01,  6.46143233e-01,\n",
       "        6.22907129e-01,  8.40399041e-01,  3.62299888e-01, -7.85036544e-01,\n",
       "        9.95948149e-01,  7.95663040e-01,  1.14915955e+00,  9.88443132e-04,\n",
       "        6.37883564e-01,  4.24799786e-01, -1.29220590e-02])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_logisitc_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f'acc = {acc:.2f} F1-score = {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.65\n"
     ]
    }
   ],
   "source": [
    "# Сделать предсказания на тренировочной выборке и\n",
    "# посчитать значение метрики accuracy и F1-score\n",
    "y_pred = sigmoid(X, theta) > 0.5\n",
    "print_logisitc_metrics(y, y_pred) # (модель логистической регрессии при помощи sklearn без регуляризации)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23091,  1629],\n",
       "       [ 3242,  4599]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "M = confusion_matrix(y, y_pred)#sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.65\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)\n",
    "y_pred = sigmoid(X_valid, theta) > 0.5\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4599,  333],\n",
       "       [ 661,  920]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "M = confusion_matrix(y_valid, y_pred)#sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисовать ROC кривую\n",
    "def calc_and_plot_roc(y_true, y_pred_proba):\n",
    "    # Посчитать значения ROC кривой и значение площади под кривой AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.title('Receiver Operating Characteristic', fontsize=15)\n",
    "    plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "    plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "    plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Вычислить вероятности принадлежности классу 1 для каждого объекта из валидационной выборки\n",
    "y_pred_proba = sigmoid(X_valid, theta)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Добавление регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Оборачивание линейной регрессии в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegOptimizer():\n",
    "    def __init__(self, alpha, n_iters):\n",
    "        self.theta = None\n",
    "        self._alpha = alpha\n",
    "        self._n_iters = n_iters\n",
    "    \n",
    "    def gradient_step(self, theta, theta_grad):\n",
    "        return theta - self._alpha * theta_grad\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def optimize(self, X, y, start_theta, n_iters):\n",
    "        theta = start_theta.copy()\n",
    "\n",
    "        for _ in range(n_iters):\n",
    "            theta_grad = self.grad_func(X, y, theta)\n",
    "            theta = self.gradient_step(theta, theta_grad)\n",
    "\n",
    "        return theta\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m = X.shape[1]\n",
    "        start_theta = np.ones(m)\n",
    "        self.theta = self.optimize(X, y, start_theta, self._n_iters)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg(RegOptimizer):\n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception('You should train the model first')\n",
    "        \n",
    "        y_pred = X.dot(self.theta)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
    "def prepare_boston_data():\n",
    "    data = load_boston()\n",
    "    X, y = data['data'], data['target']\n",
    "    # Нормализовать даннные с помощью стандартной нормализации\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dex/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "linreg = LinReg(0.01, 500)\n",
    "X, y = prepare_boston_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (506,14) and (67,) not aligned: 14 (dim 1) != 67 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50884/1042518905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_logisitc_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_50884/2258452162.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(X, theta)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Реализовать функцию sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (506,14) and (67,) not aligned: 14 (dim 1) != 67 (dim 0)"
     ]
    }
   ],
   "source": [
    "y_pred = sigmoid(X, theta) > 0.5\n",
    "print_logisitc_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 29.15, RMSE = 5.40\n"
     ]
    }
   ],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_valid)\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Оборачивание логистической регрессии в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(RegOptimizer):\n",
    "    def sigmoid(self, X, theta):\n",
    "        return 1. / (1. + np.exp(-X.dot(theta)))\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.sigmoid(X, self.theta)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception('You should train the model first')\n",
    "        \n",
    "        y_pred = self.predict_proba(X) > 0.5\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_adult_data():\n",
    "    adult = pd.read_csv('./3.9_adult.data',\n",
    "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                               'education-num', 'marital-status', 'occupation',\n",
    "                               'relationship', 'race', 'sex', 'capital-gain',\n",
    "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "    \n",
    "    # Избавиться от лишних признаков\n",
    "    adult.drop(['native-country'], axis=1, inplace=True)\n",
    "    # Сконвертировать целевой столбец в бинарные значения\n",
    "    adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "    # Сделать one-hot encoding для некоторых признаков\n",
    "    adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])\n",
    "    \n",
    "    # Нормализовать нуждающиеся в этом признаки\n",
    "    a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "    norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "    adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "    \n",
    "    # Разбить таблицу данных на матрицы X и y\n",
    "    X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "    y = adult['salary'].values\n",
    "\n",
    "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/adult.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50884/3213835293.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_adult_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_50884/404167503.py\u001b[0m in \u001b[0;36mprepare_adult_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_adult_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     adult = pd.read_csv('./data/adult.data',\n\u001b[0m\u001b[1;32m      3\u001b[0m                         names=['age', 'workclass', 'fnlwgt', 'education',\n\u001b[1;32m      4\u001b[0m                                \u001b[0;34m'education-num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'marital-status'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'occupation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                \u001b[0;34m'relationship'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'race'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'capital-gain'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/adult.data'"
     ]
    }
   ],
   "source": [
    "logreg = LogReg(1., 300)\n",
    "X, y = prepare_adult_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50884/1859739238.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(-X.dot(theta)))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50884/1115568018.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint_logisitc_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_50884/3093892086.py\u001b[0m in \u001b[0;36mprint_logisitc_metrics\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_logisitc_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'acc = {acc:.2f} F1-score = {f1:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_valid)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случаях линейной и логистической регрессии будем добавлять к функции ошибки регуляризующую часть как:\n",
    "$$\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
    "где $\\theta$ — вектор параметров линейной модели без фиктивного признака (intercept/bias term), $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Добавление регуляризатора в линейную регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После добавления регуляризации функция ошибки линейной регрессии будет выглядеть следующим образом:\n",
    "$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} + \\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2}$$\n",
    "А ее градиент по параметру $\\theta$:\n",
    "$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j} = \\frac{1}{n}X^T(X\\theta - y) + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegRegularized(LinReg):\n",
    "    def __init__(self, alpha, lambd, n_iters):\n",
    "        super(LinRegRegularized, self).__init__(alpha, n_iters)\n",
    "        self._lambd = lambd\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "        grad_term = self._lambd * np.mean(theta)\n",
    "\n",
    "        return grad + grad_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinRegRegularized(alpha=0.01, lambd=0.05, n_iters=500)\n",
    "X, y = prepare_boston_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_valid)\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Добавление регуляризатора в логистическую регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки для логистической регрессии в случае бинарной классификации с регуляризатором записывается следующим образом:\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i)))+\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
    "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
    "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответствующий градиент функции ошибки равен:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}+\\frac{\\lambda}{m}\\sum_{j}^{m}{\\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegRegularized(LogReg):\n",
    "    def __init__(self, alpha, lambd, n_iters):\n",
    "        super(LogRegRegularized, self).__init__(alpha, n_iters)\n",
    "        self._lambd = lambd\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
    "        grad_term = self._lambd * np.mean(theta)\n",
    "\n",
    "        return grad + grad_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogRegRegularized(alpha=1., lambd=1., n_iters=300)\n",
    "X, y = prepare_adult_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_valid)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
