{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Логистическая регрессия. Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки для логистической регрессии в случае бинарной классификации называется бинарной кросс-энтропией и записывается следующим образом:\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i))),$$\n",
    "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
    "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответствующий градиент функции ошибки равен:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация логистической регрессии будет основана на оптимизации функции ошибки градиентным спуском."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве экспериментальных данных возьмем датасет о доходах граждан в различных странах [Adult Income](https://archive.ics.uci.edu/ml/datasets/Adult) и сделаем необходимую предобработку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./3.9_adult.data',\n",
    "                    names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                           'education-num', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'capital-gain',\n",
    "                           'capital-loss', 'hours-per-week', 'native-country', 'salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание датасета\n",
    "\n",
    "# with open('./data/adult.names', 'r') as f:\n",
    "#     names = f.read()\n",
    "# print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "\n",
       "        marital-status        occupation    relationship    race    sex  \\\n",
       "0        Never-married      Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse   Exec-managerial         Husband   White   Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  salary  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Избавиться от лишних признаков\n",
    "adult.drop(['native-country'], axis=1, inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   salary  workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  ...  \\\n",
       "0       0             0                       0                     0  ...   \n",
       "1       0             0                       0                     0  ...   \n",
       "2       0             0                       0                     0  ...   \n",
       "3       0             0                       0                     0  ...   \n",
       "4       0             0                       0                     0  ...   \n",
       "\n",
       "   relationship_ Own-child  relationship_ Unmarried  relationship_ Wife  \\\n",
       "0                        0                        0                   0   \n",
       "1                        0                        0                   0   \n",
       "2                        0                        0                   0   \n",
       "3                        0                        0                   0   \n",
       "4                        0                        0                   1   \n",
       "\n",
       "   race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  race_ Black  \\\n",
       "0                         0                         0            0   \n",
       "1                         0                         0            0   \n",
       "2                         0                         0            0   \n",
       "3                         0                         0            1   \n",
       "4                         0                         0            1   \n",
       "\n",
       "   race_ Other  race_ White  sex_ Female  sex_ Male  \n",
       "0            0            1            0          1  \n",
       "1            0            1            0          1  \n",
       "2            0            1            0          1  \n",
       "3            0            0            0          1  \n",
       "4            0            0            1          0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030671</td>\n",
       "      <td>-1.063611</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>0.148453</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837109</td>\n",
       "      <td>-1.008707</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-2.222153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042642</td>\n",
       "      <td>0.245079</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.057047</td>\n",
       "      <td>0.425801</td>\n",
       "      <td>-1.197459</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775768</td>\n",
       "      <td>1.408176</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "0  0.030671 -1.063611       1.134739      0.148453      -0.21666   \n",
       "1  0.837109 -1.008707       1.134739     -0.145920      -0.21666   \n",
       "2 -0.042642  0.245079      -0.420060     -0.145920      -0.21666   \n",
       "3  1.057047  0.425801      -1.197459     -0.145920      -0.21666   \n",
       "4 -0.775768  1.408176       1.134739     -0.145920      -0.21666   \n",
       "\n",
       "   hours-per-week  salary  workclass_ ?  workclass_ Federal-gov  \\\n",
       "0       -0.035429       0             0                       0   \n",
       "1       -2.222153       0             0                       0   \n",
       "2       -0.035429       0             0                       0   \n",
       "3       -0.035429       0             0                       0   \n",
       "4       -0.035429       0             0                       0   \n",
       "\n",
       "   workclass_ Local-gov  ...  relationship_ Own-child  \\\n",
       "0                     0  ...                        0   \n",
       "1                     0  ...                        0   \n",
       "2                     0  ...                        0   \n",
       "3                     0  ...                        0   \n",
       "4                     0  ...                        0   \n",
       "\n",
       "   relationship_ Unmarried  relationship_ Wife  race_ Amer-Indian-Eskimo  \\\n",
       "0                        0                   0                         0   \n",
       "1                        0                   0                         0   \n",
       "2                        0                   0                         0   \n",
       "3                        0                   0                         0   \n",
       "4                        0                   1                         0   \n",
       "\n",
       "   race_ Asian-Pac-Islander  race_ Black  race_ Other  race_ White  \\\n",
       "0                         0            0            0            1   \n",
       "1                         0            0            0            1   \n",
       "2                         0            0            0            1   \n",
       "3                         0            1            0            0   \n",
       "4                         0            1            0            0   \n",
       "\n",
       "   sex_ Female  sex_ Male  \n",
       "0            0          1  \n",
       "1            0          1  \n",
       "2            0          1  \n",
       "3            0          1  \n",
       "4            1          0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию sigmoid\n",
    "def sigmoid(X, theta):\n",
    "    return 1. / (1. + np.exp(-X.dot(theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию, вычисляющую градиент бинарной кросс-энтропии\n",
    "def calc_binary_cross_entropy_grad(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(sigmoid(X, theta) - y)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.18220152e+00, -7.85036544e-01,  3.36378365e-01,  1.02420428e+00,\n",
       "        9.87311090e-01,  1.59897859e-01,  6.08930383e-01,  6.37883564e-01,\n",
       "        8.11280626e-01,  5.89057982e-01,  3.38583874e-01,  3.24397258e-01,\n",
       "        2.36520366e-01,  1.14915955e+00, -1.59850366e-02,  1.02543563e+00,\n",
       "        5.20449527e-01, -1.29220590e-02,  6.93612812e-03,  9.88443132e-04,\n",
       "        5.34420479e-01,  8.40399041e-01,  6.46143233e-01,  5.53494533e-01,\n",
       "       -4.28230037e-01, -1.39716497e+00,  7.95663040e-01,  9.48510850e-01,\n",
       "        8.85025416e-01,  9.33962074e-01, -2.97874470e-01,  7.79500017e-02,\n",
       "        2.58558666e-01,  4.91984312e-01,  7.61509306e-01,  9.74747564e-01,\n",
       "        3.30697269e-01,  9.64814314e-01, -7.81877921e-02,  6.90788800e-01,\n",
       "        6.11752440e-01,  6.22907129e-01,  3.38009780e-01,  5.62066615e-01,\n",
       "       -6.37888463e-01,  8.35398252e-01,  3.95775461e-01,  9.09710550e-01,\n",
       "        2.21719660e+00,  9.95948149e-01,  6.21876481e-01,  4.08394474e-01,\n",
       "        6.18223280e-01,  7.68917996e-01,  1.05574662e+00,  1.42333149e+00,\n",
       "        1.08787945e+00,  2.32468515e-01,  8.58881427e-01,  3.62299888e-01,\n",
       "        4.35222964e-01,  8.98087390e-01,  4.24799786e-01,  2.28275110e-02,\n",
       "       -3.15524980e-01,  9.78308166e-01,  1.61096748e+00])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_logisitc_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f'acc = {acc:.2f} F1-score = {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.65\n"
     ]
    }
   ],
   "source": [
    "# Сделать предсказания на тренировочной выборке и\n",
    "# посчитать значение метрики accuracy и F1-score\n",
    "y_pred = sigmoid(X, theta) > 0.5\n",
    "print_logisitc_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.65\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)\n",
    "y_pred = sigmoid(X_valid, theta) > 0.5\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисовать ROC кривую\n",
    "def calc_and_plot_roc(y_true, y_pred_proba):\n",
    "    # Посчитать значения ROC кривой и значение площади под кривой AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.title('Receiver Operating Characteristic', fontsize=15)\n",
    "    plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "    plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "    plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Вычислить вероятности принадлежности классу 1 для каждого объекта из валидационной выборки\n",
    "y_pred_proba = sigmoid(X_valid, theta)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Добавление регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Оборачивание линейной регрессии в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegOptimizer():\n",
    "    def __init__(self, alpha, n_iters):\n",
    "        self.theta = None\n",
    "        self._alpha = alpha\n",
    "        self._n_iters = n_iters\n",
    "    \n",
    "    def gradient_step(self, theta, theta_grad):\n",
    "        return theta - self._alpha * theta_grad\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def optimize(self, X, y, start_theta, n_iters):\n",
    "        theta = start_theta.copy()\n",
    "\n",
    "        for _ in range(n_iters):\n",
    "            theta_grad = self.grad_func(X, y, theta)\n",
    "            theta = self.gradient_step(theta, theta_grad)\n",
    "\n",
    "        return theta\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m = X.shape[1]\n",
    "        start_theta = np.ones(m)\n",
    "        self.theta = self.optimize(X, y, start_theta, self._n_iters)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg(RegOptimizer):\n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception('You should train the model first')\n",
    "        \n",
    "        y_pred = X.dot(self.theta)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
    "def prepare_boston_data():\n",
    "    data = load_boston()\n",
    "    X, y = data['data'], data['target']\n",
    "    # Нормализовать даннные с помощью стандартной нормализации\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dex/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "linreg = LinReg(0.01, 500)\n",
    "X, y = prepare_boston_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 22.09, RMSE = 4.70\n"
     ]
    }
   ],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_valid)\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Оборачивание логистической регрессии в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(RegOptimizer):\n",
    "    def sigmoid(self, X, theta):\n",
    "        return 1. / (1. + np.exp(-X.dot(theta)))\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.sigmoid(X, self.theta)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception('You should train the model first')\n",
    "        \n",
    "        y_pred = self.predict_proba(X) > 0.5\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_adult_data():\n",
    "    adult = pd.read_csv('./3.9_adult.data',\n",
    "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                               'education-num', 'marital-status', 'occupation',\n",
    "                               'relationship', 'race', 'sex', 'capital-gain',\n",
    "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "    \n",
    "    # Избавиться от лишних признаков\n",
    "    adult.drop(['native-country'], axis=1, inplace=True)\n",
    "    # Сконвертировать целевой столбец в бинарные значения\n",
    "    adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "    # Сделать one-hot encoding для некоторых признаков\n",
    "    adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])\n",
    "    \n",
    "    # Нормализовать нуждающиеся в этом признаки\n",
    "    a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "    norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "    adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "    \n",
    "    # Разбить таблицу данных на матрицы X и y\n",
    "    X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "    y = adult['salary'].values\n",
    "\n",
    "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogReg(1., 300)\n",
    "X, y = prepare_adult_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.84 F1-score = 0.65\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_valid)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случаях линейной и логистической регрессии будем добавлять к функции ошибки регуляризующую часть как:\n",
    "$$\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
    "где $\\theta$ — вектор параметров линейной модели без фиктивного признака (intercept/bias term), $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Добавление регуляризатора в линейную регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После добавления регуляризации функция ошибки линейной регрессии будет выглядеть следующим образом:\n",
    "$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} + \\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2}$$\n",
    "А ее градиент по параметру $\\theta$:\n",
    "$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j} = \\frac{1}{n}X^T(X\\theta - y) + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegRegularized(LinReg):\n",
    "    def __init__(self, alpha, lambd, n_iters):\n",
    "        super(LinRegRegularized, self).__init__(alpha, n_iters)\n",
    "        self._lambd = lambd\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "        grad_term = self._lambd * np.mean(theta)\n",
    "\n",
    "        return grad + grad_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dex/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "linreg = LinRegRegularized(alpha=0.01, lambd=0.05, n_iters=500)\n",
    "X, y = prepare_boston_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 26.92, RMSE = 5.19\n"
     ]
    }
   ],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_valid)\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Добавление регуляризатора в логистическую регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки для логистической регрессии в случае бинарной классификации с регуляризатором записывается следующим образом:\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i)))+\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
    "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
    "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответствующий градиент функции ошибки равен:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}+\\frac{\\lambda}{m}\\sum_{j}^{m}{\\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegRegularized(LogReg):\n",
    "    def __init__(self, alpha, lambd, n_iters):\n",
    "        super(LogRegRegularized, self).__init__(alpha, n_iters)\n",
    "        self._lambd = lambd\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
    "        grad_term = self._lambd * np.mean(theta)\n",
    "\n",
    "        return grad + grad_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogRegRegularized(alpha=1., lambd=1., n_iters=300)\n",
    "X, y = prepare_adult_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_valid)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_logisitc_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f'acc = {acc:.2f} F1-score = {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Сделать предсказания на тренировочной выборке и\n",
    "# посчитать значение метрики accuracy и F1-score\n",
    "y_pred = sigmoid(X, theta) > 0.5\n",
    "print_logisitc_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Задание 3.9.1 \n",
    "Постройте модель логистической регрессии при помощи sklearn. Используйте параметры по умолчанию, обучите на всей выборке и посчитайте F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "adult = pd.read_csv('./3.9_adult.data',\n",
    "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                               'education-num', 'marital-status', 'occupation',\n",
    "                               'relationship', 'race', 'sex', 'capital-gain',\n",
    "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "    \n",
    "# Избавиться от лишних признаков\n",
    "adult.drop(['native-country'], axis=1, inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])\n",
    "\n",
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "\n",
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "############ 3.9.1 \n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "logreg.fit(X_train, y_train) \n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "# print_logisitc_metrics(y_valid, y_pred)\n",
    "f1_score = metrics.f1_score(y_valid, y_pred) \n",
    "print(f'f1_score = {f1_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3.9.7\n",
    "Провалидируйте логистическую регрессию из sklearn на 5-fold кросс-валидации. В логистической регрессии надо выставить random_state=42. Какой получился средний F1-score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(X, y):\n",
    "    # Разбить данные на train/valid\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "    # Создать и обучить линейную регрессию    \n",
    "    logreg = LogisticRegression(max_iter=500)\n",
    "    logreg.fit(X_train, y_train) \n",
    "    \n",
    "    # Сделать предсказания по валидционной выборке\n",
    "    y_pred = logreg.predict(X_valid)\n",
    "\n",
    "\n",
    "    # Посчитать значение ошибок MSE и RMSE для валидационных данных\n",
    "    print_regression_metrics(y_valid, y_pred)\n",
    "    \n",
    "    # F1-score\n",
    "    f1_score = metrics.f1_score(y_valid, y_pred) \n",
    "    print(f'f1_score = {f1_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate(X, y)\n",
    "#f1_score = 0.67 is correct answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Задание 3.9.2 \n",
    "Посчитайте confusion matrix для классификатора из задачи 3.9.1. Для получения матрицы можно воспользоваться методом sklearn.metrics.confusion_matrix(y_true, y_pred), либо посчитать каждый элемент вручную. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 3.9.2\n",
    "#https://www.machinelearningmastery.ru/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a/\n",
    "\n",
    "############ 3.9.2 (в задании не просили делить датасет на train и test, нужно обучиться и валидироваться на всем датасете)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg.fit(X, y) \n",
    "y_pred = logreg.predict(X)\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([[23028,  1692],\n",
    "       [ 3124,  4717]]) is correct answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Задание 3.9.5\n",
    "Переберите коэффициенты L2-регуляризации от 0.01 до 1 с шагом 0.01 и определите, на каком из них модель логистической регрессии из sklearn даёт наибольший F1-score.\n",
    "documentation:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRONG\n",
    "WHY?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./3.9_adult.data',\n",
    "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                               'education-num', 'marital-status', 'occupation',\n",
    "                               'relationship', 'race', 'sex', 'capital-gain',\n",
    "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "    \n",
    "# Избавиться от лишних признаков\n",
    "adult.drop(['native-country'], axis=1, inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])\n",
    "\n",
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "\n",
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "c_list = np.arange(0.01, 1.01, 0.01)\n",
    "max_f1 = -1\n",
    "max_c = -1\n",
    "for c in c_list:\n",
    "    LRC = LogisticRegression(C=c, penalty='l2', random_state=823, max_iter=500)\n",
    "    LRC.fit(X, y)\n",
    "    y_pred = LRC.predict(X)\n",
    "    f1 = metrics.f1_score(y, y_pred)\n",
    "    if f1 > max_f1:\n",
    "        max_f1 = f1\n",
    "        max_c = c\n",
    "\n",
    "print(max_c) #Должно получаться 0.88."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whats below is uncorrect for task\n",
    "lam_395 = 0.01\n",
    "how_much_cycle = int(1/lam_395)\n",
    "F1_score_array = []\n",
    "###\n",
    "max_f1 = -1\n",
    "max_c = -1\n",
    "###\n",
    "for i in range(0, how_much_cycle):\n",
    "    logreg = LogisticRegression(C=lam_395, penalty='l2', random_state=823, max_iter=500)\n",
    "    X, y = prepare_adult_data()\n",
    "    #X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "    logreg.fit(X, y)\n",
    "    \n",
    "    # сделать предсказания и посчитать ошибку F1-score\n",
    "    y_pred = logreg.predict(X)\n",
    "    # print_logisitc_metrics(y_valid, y_pred)\n",
    "    f1_score = metrics.f1_score(y, y_pred)#sklearn.metrics.f1_score\n",
    "    \n",
    "    ###\n",
    "    if f1_score > max_f1:\n",
    "        max_f1 = f1_score\n",
    "        max_c = i\n",
    "    ###   \n",
    "        \n",
    "    #print(f1_score)\n",
    "    F1_score_array.append(f1_score)\n",
    "    lam_395+= 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "print(max_c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#len(F1_score_array)\n",
    "#F1_score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score_array = 0.66\n"
     ]
    }
   ],
   "source": [
    "max_f1_score = max(F1_score_array) #now need to find lambda on which this F1-score occurs\n",
    "print(f'F1_score_array = {max_f1_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam_number = F1_score_array.index(max(F1_score_array)) + 1\n",
    "lam_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Задание 3.9.6\n",
    "Замените в столбце native-country страны, у которых меньше ста записей на other, поменяйте эту колонку на dummy-переменные, обучите классификатор на всей выборке и посчитайте F1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.metrics as metrics\n",
    "# from sklearn.linear_model import LogisticRegression #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./3.9_adult.data',\n",
    "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                               'education-num', 'marital-status', 'occupation',\n",
    "                               'relationship', 'race', 'sex', 'capital-gain',\n",
    "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "\n",
    "# # Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "\n",
    "####task 3.9.6\n",
    "a = adult['native-country'].value_counts()\n",
    "countries_to_replace = a[a < 100].index\n",
    "adult['native-country'] = adult['native-country'].replace(countries_to_replace, 'other')\n",
    "####task 3.9.6\n",
    "\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'])####task 3.9.6\n",
    "\n",
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "\n",
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = adult['native-country'].value_counts()\n",
    "# countries_to_replace = a[a < 100].index\n",
    "# adult['native-country'] = adult['native-country'].replace(countries_to_replace, 'other')\n",
    "# ad_replaced = adult['native-country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию sigmoid\n",
    "def sigmoid(X, theta):\n",
    "    return 1. / (1. + np.exp(-X.dot(theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию, вычисляющую градиент бинарной кросс-энтропии\n",
    "def calc_binary_cross_entropy_grad(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(sigmoid(X, theta) - y)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_logisitc_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f'acc = {acc:.2f} F1-score = {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания на тренировочной выборке и\n",
    "# посчитать значение метрики accuracy и F1-score\n",
    "y_pred = sigmoid(X, theta) > 0.5\n",
    "print_logisitc_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
