{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a490c9-d8e0-46a3-91db-b4f882794bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
      "       'average_montly_hours', 'time_spend_company', 'Work_accident',\n",
      "       'promotion_last_5years', 'dept', 'salary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df = pd.read_csv('m5.7_HR-dataset.csv')\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "target = 'left'\n",
    "features = df.columns.drop(target)\n",
    "features = features.drop('empid')  # Удалим идентификатор пользователя как нерепрезентативный признак\n",
    "print(features)\n",
    "\n",
    "X, y = df[features].copy(), df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8863ef-4fed-4e48-8ddb-3324cc45ad6d",
   "metadata": {},
   "source": [
    "Заменим идентификатор отдела, к которому относился сотрудник, на количество людей в отделе, а зарплату — на ординальную категорию. Масштабируем признаки для последующего сравнения результатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65fb0e8a-9ede-45c1-815f-bdbf5917064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_ordinals = {'low': 1, 'medium': 2, 'high': 3}\n",
    "\n",
    "X['dept'] = X['dept'].apply(X['dept'].value_counts().get)\n",
    "X['salary'] = X['salary'].apply(salary_ordinals.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704d05ec-4807-4795-84f9-f49b23e59465",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(data=scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff35ea6e-c795-49d3-9761-279445a293ac",
   "metadata": {},
   "source": [
    "В дальнейшем будем оценивать качество модели на кросс-валидации на пяти фолдах при помощи точности (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0693594a-f4f5-4406-8e84-bcf2993f0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_accuracy(clf, X, y, cv=5):\n",
    "    return cross_val_score(clf, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641370e4-9f2e-454d-916c-d00750305070",
   "metadata": {},
   "source": [
    "Посмотрим на то, как работает бэггинг над решающими деревьями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a778593-5904-405f-9aba-7d60f99940e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree: 0.9731310659108592\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=30)\n",
    "print(\"Decision tree:\", estimate_accuracy(tree, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fea17b0-26a0-4bd3-a0fa-1b3f64822179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree bagging: 0.9880660886962321\n"
     ]
    }
   ],
   "source": [
    "bagging_trees = BaggingClassifier(tree)\n",
    "print(\"Decision tree bagging:\", estimate_accuracy(bagging_trees, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac65366-655f-4346-a427-44e650bc8cd3",
   "metadata": {},
   "source": [
    "Увеличить различность построенных деревьев можно, указав параметры max_features и max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e8bf8e-731f-4a75-bf71-7efc68562591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tree: 0.9778657330221184\n"
     ]
    }
   ],
   "source": [
    "random_tree = DecisionTreeClassifier(max_features=int(np.sqrt(len(features))), max_depth=30)\n",
    "print(\"Random tree:\", estimate_accuracy(random_tree, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3512e1a-7170-4a70-907d-bd917d1c01cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tree bagging: 0.9902662443036567\n"
     ]
    }
   ],
   "source": [
    "bagging_random_trees = BaggingClassifier(random_tree)\n",
    "print(\"Random tree bagging:\", estimate_accuracy(bagging_random_trees, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11de5f4-6206-4881-b983-58d56b4f157e",
   "metadata": {},
   "source": [
    "Стандартная эвристика: в задаче классификации брать квадратный корень числа признаков, а в задаче регрессии — треть числа признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a3e8f8-90fb-41c4-829f-8dae0c2d41e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.9920663109925532\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    max_features=int(np.sqrt(len(features))),\n",
    "    max_depth=30)\n",
    "print(\"Random Forest:\", estimate_accuracy(random_forest, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4735eec-b870-449b-b36b-f8356d3730c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dex/.local/lib/python3.8/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9929995333022201"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features=int(np.sqrt(len(features))),\n",
    "    max_depth=30,\n",
    "    oob_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_forest.fit(X, y)\n",
    "random_forest.oob_score_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6897c5ad-087a-482a-b39a-f50b8cd00f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.7709770367900411\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='saga', max_iter=200)\n",
    "lr.fit(X, y)\n",
    "print(\"LR:\", estimate_accuracy(lr, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b74ba6-b814-4c6b-b261-f8b48c5bb40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging for LR: 0.7701104368122708\n"
     ]
    }
   ],
   "source": [
    "random_logreg = BaggingClassifier(\n",
    "    lr,\n",
    "    n_estimators=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Bagging for LR:\", estimate_accuracy(random_logreg, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6394342b-9b8a-47ec-9cc5-38c9bd2778ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging for LR: 0.7569754140268978\n"
     ]
    }
   ],
   "source": [
    "#Попробуем убрать часть признаков.\n",
    "random_logreg = BaggingClassifier(\n",
    "    lr,\n",
    "    n_estimators=10,\n",
    "    n_jobs=-1,\n",
    "    max_features=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Bagging for LR:\", estimate_accuracy(random_logreg, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3513e0-f478-4708-a390-91fd279b5bd2",
   "metadata": {},
   "source": [
    "Сравнение логистической регрессии и случайного леса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45dc707b-f294-4b6e-b086-87216b6f7a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(X, y, clf, proba=False, points_size=7, xlabel='x', ylabel='y'):\n",
    "    \"\"\"Fits the classifier on the data (X, y) and plots the result on a 2-D plane.\"\"\"\n",
    "    def get_grid(data):\n",
    "        x_std, y_std = data.std(axis=0)\n",
    "        x_min, x_max = data[:, 0].min() - x_std / 2, data[:, 0].max() + x_std / 2\n",
    "        y_min, y_max = data[:, 1].min() - y_std / 2, data[:, 1].max() + y_std / 2\n",
    "        return np.meshgrid(np.linspace(x_min, x_max, num=200),\n",
    "                           np.linspace(y_min, y_max, num=200))\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    xx, yy = get_grid(X)\n",
    "    if proba:\n",
    "        predicted = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1].reshape(xx.shape)\n",
    "    else:\n",
    "        predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        \n",
    "    plt.figure(figsize=(10.0, 10.0))\n",
    "    plt.pcolormesh(xx, yy, predicted, cmap=plt.cm.coolwarm, alpha=0.1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=points_size, cmap=plt.cm.coolwarm, alpha=0.90)\n",
    "    plt.ylim([yy.min(),yy.max()])\n",
    "    plt.xlim([xx.min(),xx.max()])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819f61f-f0e4-4dea-bcde-de55f7c73733",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Практика\n",
    "\n",
    "1) Загрузите датасет digits с помощью функции load_digits из sklearn.datasets и подготовьте матрицу признаков и ответы на обучающей выборке (вам потребуются поля data и target в объекте, который возвращает load_digits). \n",
    "\n",
    "2) Информацию о датасете вы можете получить, обратившись к полю DESCR у возвращаемого объекта load_digits. Нам предстоит решать задачу классификации изображений с цифрами по численным признакам.\n",
    "\n",
    "3) Для оценки качества мы будем использовать cross_val_score из sklearn.model_selection с параметром cv=10. Эта функция реализует k-fold cross validation c k равным значению параметра cv. Предлагается использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет k чисел — качество в каждом k из экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score.\n",
    "\n",
    "С небольшой вероятностью вы можете натолкнуться на случай, когда полученное вами качество в каком-то из пунктов не попадёт в диапазон, заданный для правильных ответов — в этом случае попробуйте перезапустить ячейку с cross_val_score несколько раз и выбрать наиболее «типичное» значение. Если это не помогает, то где-то была допущена ошибка.\n",
    "\n",
    "Чтобы ускорить вычисление cross_val_score, следует попробовать использовать параметр __n_jobs__. Число, которое вы подаёте в качестве этого параметра, соответствует количеству потоков вашего процессора, которое будет задействовано в вычислении. Если указать n_jobs = -1, тогда будет задействовано максимальное число потоков.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24103390-b60b-444e-83e0-78bbdd2bc3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим датасет\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "n_samples = 1500\n",
    "data = datasets.load_digits()\n",
    "#dataset.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdcd5799-bbab-4276-a367-20334fb1ec54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fd14e81-55ca-437a-b956-6c13682fe0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['data'], data['target']\n",
    "# # Нормализовать даннные с помощью стандартной нормализации\n",
    "# X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "# # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "# X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e0a2951-6961-431f-acb4-e4bf6845bafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8358348851644941"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "arr = cross_val_score(tree, X, y, cv=10)\n",
    "arr.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c15e71-5cae-4eb2-81c5-ee373694611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_accuracy(clf, X, y, cv=10):\n",
    "    return cross_val_score(clf,X,y,cv=5,scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b4463-1d74-4dcf-b734-b3bf2edea5c3",
   "metadata": {},
   "source": [
    "#### Задание 5.7.1\n",
    "\n",
    "Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Эту величину введите в поле для ответа (ваше значение должно попасть в заданный интервал)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d889a285-d99f-471a-8b3b-c0e54aed7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8241247672253259"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "arr = cross_val_score(clf, X, y, cv=10)\n",
    "arr.mean() \n",
    "#0.82 is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af090aeb-f0af-44e0-a84c-33e2cfd4844e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Задание 5.7.2\n",
    "\n",
    "\n",
    "Теперь давайте обучим BaggingClassifier на основе DecisionTreeClassifier. Из sklearn.ensemble импортируйте BaggingClassifier, все параметры задайте по умолчанию. Нужно изменить только количество базовых моделей, задав его равным 100.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html?highlight=baggingclassifier\n",
    "\n",
    "В поле для ответа введите качество работы получившегося классификатора (ваше значение должно попасть в заданный интервал).\n",
    "\n",
    "Подумайте, какие выводы можно сделать из соотношения качества одиночного дерева и бэггинга деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "057d2a2e-4910-44c7-ab59-e6ea547dfb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.927048417132216"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bclf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, random_state=0).fit(X,y)\n",
    "\n",
    "arr = cross_val_score(bclf, X, y, cv=10)\n",
    "arr.mean() \n",
    "#0.92 is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb53a9-5f5e-4727-beb4-a88e2ad06ef5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Задание 5.7.3\n",
    "\n",
    "Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на sqrt(d) случайных признаках.\n",
    "\n",
    "В поле для ответа введите качество работы получившегося классификатора (ваше значение должно попасть в заданный интервал).\n",
    "\n",
    "Корень из числа признаков — часто используемая эвристика в задачах классификации. В задачах регрессии же часто берут число признаков, делённое на три, log(d) тоже имеет место быть. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков, добиваясь лучшего качества на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8407f3af-75f3-4fb2-ac66-49e4b9af8ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924866542520174"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "clf = DecisionTreeClassifier()\n",
    "stoch_train_len = int(math.sqrt(X.shape[1]))\n",
    "bagging_clf = BaggingClassifier(clf, n_estimators=100, max_features=stoch_train_len)\n",
    "\n",
    "arr = cross_val_score(bagging_clf, X, y, cv=10)\n",
    "arr.mean() \n",
    "#0.93 is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b89a4-080b-4433-aa9c-99def90de1ba",
   "metadata": {},
   "source": [
    "#### Задание 5.7.4\n",
    "\n",
    "В предыдущем пункте мы выбирали подмножество один раз для каждого очередного дерева. Следующим нашим шагом будет построение бэггинга на основе деревьев, которые выбирают случайное подмножество признаков для каждой вершины дерева.\n",
    "\n",
    "Для этого нам потребуется перенести отвечающий за это параметр из BaggingClassifier в DecisionTreeClassifier. Для этого вам из документации нужно выяснить, какой параметр __DecisionTreeClassifier__ за это отвечает.\n",
    "\n",
    "В поле для ответа введите значение этого параметра (ваше значение должно попасть в заданный интервал).\n",
    "\n",
    "По-прежнему сэмплируем sqrt(d) признаков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "912b56ec-b8a9-45ac-885f-cccaa0dc8acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9499162011173183"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://notebook.community/agushman/coursera/src/cours_2/week_4/bagging_and_rand_forest\n",
    "import math\n",
    "clf = DecisionTreeClassifier()\n",
    "stoch_train_len = int(math.sqrt(X.shape[1]))\n",
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(max_features=stoch_train_len), n_estimators=100) \n",
    "#or BaggingClassifier(DecisionTreeClassifier(max_features=math.sqrt(X.shape[1])/X.shape[1]), n_estimators=100) #???\n",
    "\n",
    "arr = cross_val_score(bagging_clf, X, y, cv=10)\n",
    "arr.mean() \n",
    "#0.95 is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e39219-d3d0-4832-bffc-bace7f11e87a",
   "metadata": {},
   "source": [
    "#### Задание 5.7.5\n",
    "\n",
    "Полученный в задании 4 классификатор — бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков, и разбиение ищется только по ним). Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble?\n",
    "\n",
    "Сделайте это, а затем изучите, как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева.\n",
    "\n",
    "Для наглядности лучше построить графики зависимости качества от значений параметров, но для сдачи задания это делать необязательно.\n",
    "На основе наблюдений выберите правильные утверждения из приведенных ниже и впишите в поле для ответа их номера в порядке возрастания через пробел :\n",
    "\n",
    "1) Случайный лес сильно переобучается с ростом количества деревьев\n",
    "\n",
    "2) При очень маленьком числе деревьев (5, 10, 15) случайный лес работает хуже, чем при большем числе деревьев\n",
    "\n",
    "3) С ростом количества деревьев в случайном лесе в какой-то момент деревьев становится достаточно для высокого качества классификации, а затем качество существенно не меняется.\n",
    "\n",
    "4) При большом количестве признаков (для данного датасета — 40-50) качество классификации становится хуже, чем при малом количестве признаков (10-15). Это связано с тем, что чем меньше признаков выбирается в каждом узле, тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), и тем лучше работает их композиция.\n",
    "\n",
    "5) При большом количестве признаков (40, 50, 60) качество классификации лучше, чем при малом количестве признаков (5, 10). Это связано с тем, что чем больше признаков, тем больше информации об объектах, а значит алгоритм может делать прогнозы более точно.\n",
    "\n",
    "6) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса намного лучше, чем без ограничения глубины, т.к. деревья получаются не переобученными. С ростом глубины деревьев качество ухудшается.\n",
    "\n",
    "7) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, чем без ограничений, т.к. деревья получаются недообученными. С ростом глубины качество сначала улучшается, а затем не меняется существенно, т.к. из-за усреднения прогнозов и различий деревьев их переобученность в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении они компенсируют переобученность друг друга)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "481917f8-178a-4053-a7a3-e43483feca37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487988826815641"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "stoch_train_len = int(math.sqrt(X.shape[1]))\n",
    "rf_clf = RandomForestClassifier(random_state=stoch_train_len, n_estimators=100)\n",
    "\n",
    "arr = cross_val_score(rf_clf, X, y, cv=10)\n",
    "arr.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8fba3c4b-df6d-47a8-b127-37227bd2af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 3 4 7 is correct answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
